# -*- coding: utf-8 -*-
"""LMTS_fix_9_7-25.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1z2mFDsIwbhzEDB9Cj8P5o8GFR77B0gtv

# Exploratory Data Analysis

## Step 1: Load and Inspect the **Dataset**
"""

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import warnings
warnings.filterwarnings("ignore")
import matplotlib.pyplot as plt
import seaborn as sns
import math

"""### Load Data"""

# Melakukan import csv
df = pd.read_csv("Nvidia_stock_data.csv")
df.sample(5)

"""### Descriptive Statictics



"""

# Mengecek apakah ada data yang NaN/Null
print(df.isnull().values.any())
print(df.isna().sum())

# Mengecek Duplicated data
df.duplicated().sum()

print(f"The Number of Rows are {df.shape[0]}, and columns are {df.shape[1]}.")

# Mengecek Datatype tiap kolom berserta non-null kolom
df.info()

"""bisa dilihat tipe data date masih object, maka harus diganti dengan date time

***Observation***

1. Jumlah barisnya 6637, dan jumlah kolomnya 6.
2. Tidak ada missing value
3. Perlu diubah tipe data dari Date yang tadinya object kita harus ubah ke datetime

### Data Prepocessing

#### Convert 'Date' to datetime and sort
"""

df['Date'] = pd.to_datetime(df['Date'])
df.sort_values(by='Date', inplace=True)

df.info()

df.describe()

data_array = df

nilai_maksimum_np = data_array.max()
nilai_minimum_np = data_array.min()

print(f"Nilai maksimum (NumPy): {nilai_maksimum_np}")
print(f"Nilai minimum (NumPy): {nilai_minimum_np}")

"""# Visualizations

### 1. Line Chart of Closing Price Over Time
"""

plt.figure(figsize=(18, 6))
plt.plot(df['Date'], df['Close'], label="Close Price", linewidth=2)
plt.title("NVIDIA Closing Price Over Time", fontsize=16)
plt.xlabel("Date")
plt.ylabel("Close Price ($)")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

"""### 2. Volume vs Closing Price"""

plt.figure(figsize=(10, 6))
sns.scatterplot(x='Volume', y='Close', data=df, alpha=0.3)
plt.title("Volume vs Close Price", fontsize=14)
plt.tight_layout()
plt.show()

"""### 3. Correlation Heatmap"""

plt.figure(figsize=(8, 6))
sns.heatmap(df.drop(columns=['Date']).corr(), annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Correlation Heatmap", fontsize=14)
plt.tight_layout()
plt.show()

for column in df.columns[2:]:
    plt.figure(figsize=(10, 6))
    plt.plot(df['Date'], df[column])
    plt.xlabel('Date')
    plt.ylabel(column)
    plt.title(f'{column} vs. Date')
    plt.tight_layout()
    plt.show()

"""# Model Fitting

## LSTM
"""

from sklearn.model_selection import GridSearchCV
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import Dense, Dropout, LSTM
from math import ceil

from tensorflow.keras.callbacks import EarlyStopping

early_stop = EarlyStopping(
    monitor='val_loss',      # pantau val_loss
    patience=10,             # berhenti kalau 10 epoch berturut-turut tidak membaik
    restore_best_weights=True # balikin bobot terbaik
)

shape = df.shape[0]
df_new=df[['Open']]
dataset = df_new.values
train = df_new.iloc[:ceil(shape * 0.9)]
valid = df_new.iloc[ceil(shape * 0.9):]
print('-----------------------------------------------------------------------------')
print('-----------STOCK PRICE PREDICTION BY LONG SHORT TERM MEMORY (LSTM)-----------')
print('-----------------------------------------------------------------------------')
print('Shape of Training Set',train.shape)
print('Shape of Validation Set',valid.shape)
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(df_new)
x_train, y_train = [], []
for i in range(40,len(train)):
    x_train.append(scaled_data[i-40:i,0])
    y_train.append(scaled_data[i,0])
x_train, y_train = np.array(x_train), np.array(y_train)
x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))
model = Sequential()
model.add(LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1],1)))
model.add(LSTM(units=50))
model.add(Dense(1))
model.compile(loss='mean_squared_error', optimizer='adam')
history = model.fit(
    x_train, y_train,
    epochs=50,
    batch_size=32,
    verbose=2,
    validation_split=0.1,
    callbacks=[early_stop])

inputs = df_new[len(df_new) - len(valid) - 40:]
inputs
inputs.values.reshape(-1,1)
inputs  = scaler.transform(inputs)
X_test = []
for i in range(40,inputs.shape[0]):
    X_test.append(inputs[i-40:i,0])
X_test = np.array(X_test)
X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))
opening_price = model.predict(X_test)
opening_price= scaler.inverse_transform(opening_price)
rms=np.sqrt(np.mean(np.power((valid-opening_price),2)))
print('RMSE value on validation set:',rms)

#Visualize the prediction
plt.figure(figsize=(10,5), dpi=100)
valid['Predictions'] = opening_price
plt.plot(df_new['Open'])
plt.plot(valid[['Open','Predictions']])
plt.xlabel('Date')
plt.ylabel('Stock Price')
plt.title('Stock Price Prediction by Long Short Term Memory (LSTM)')
plt.legend(['Model Training Data','Actual Data','Predicted Data'])

"""## Prophet"""

pip install prophet

from prophet import Prophet

def prophet_prediction(df):
    shape=df.shape[0]
    df_new = df[['Date', 'Close']].copy()
    df_new.reset_index(inplace=True)
    df_new['Date'] = pd.to_datetime(df_new.Date,format='%Y-%m-%d')
    df_new.index = df_new['Date']
    df_new.rename(columns={'Close': 'y', 'Date': 'ds'}, inplace=True)
    train_set=df_new.iloc[:ceil(shape*0.75)]
    valid_set=df_new.iloc[ceil(shape*0.75):]
    print('-------------------------------------------------------')
    print('-----------STOCK PRICE PREDICTION BY FB PROPHET-----------')
    print('-------------------------------------------------------')
    print('Shape of Training Set',train_set.shape)
    print('Shape of Validation Set',valid_set.shape)
    model = Prophet()
    model.fit(train_set)
    close_prices = model.make_future_dataframe(periods=len(valid_set))
    forecast = model.predict(close_prices)
    forecast_valid = forecast['yhat'][ceil(shape*0.75):]
    rms=np.sqrt(np.mean(np.power((np.array(valid_set['y'])-np.array(forecast_valid)),2)))
    print('RMSE value on validation set:',rms)
    print('-----------------------------------------------------------')
    print('-----------------------------------------------------------')
    valid_set['Predictions'] = forecast_valid.values
    plt.plot(train_set['y'])
    plt.plot(valid_set[['y', 'Predictions']])
    plt.xlabel('Date',size=20)
    plt.ylabel('Stock Price',size=20)
    plt.title('Stock Price Prediction by FB Prophet',size=20)
    plt.legend(['Model Training Data','Actual Data','Predicted Data'])

prophet_prediction(df)

"""## EXPONENTIAL SMOOTHING




"""

def exp_smoothing_prediction(df):
    from statsmodels.tsa.holtwinters import ExponentialSmoothing
    import warnings
    from contextlib import redirect_stdout
    import os

    shape = df.shape[0]
    df_new = df[['Date', 'Close']].copy()
    df_new.reset_index(inplace=True)
    df_new['Date'] = pd.to_datetime(df_new.Date, format='%Y-%m-%d')
    df_new.index = df_new['Date']
    df_new.rename(columns={'Close': 'y', 'Date': 'ds'}, inplace=True)
    train_set = df_new.iloc[:ceil(shape*0.75)]
    valid_set = df_new.iloc[ceil(shape*0.75):]
    print('-------------------------------------------------------')
    print('-----------STOCK PRICE PREDICTION BY EXPONENTIAL SMOOTHING-----------')
    print('-------------------------------------------------------')
    print('Shape of Training Set', train_set.shape)
    print('Shape of Validation Set', valid_set.shape)

    # Model Exponential Smoothing (sembunyikan output)
    model = ExponentialSmoothing(train_set['y'], trend='add', seasonal=None, damped_trend=True)
    warnings.filterwarnings('ignore')
    with redirect_stdout(open(os.devnull, 'w')):
        fitted_model = model.fit()

    # Forecast
    forecast = fitted_model.forecast(steps=len(valid_set))
    forecast_valid = forecast

    rms = np.sqrt(np.mean(np.power((np.array(valid_set['y']) - np.array(forecast_valid)), 2)))
    print('RMSE value on validation set:', rms)
    print('-----------------------------------------------------------')
    print('-----------------------------------------------------------')
    valid_set['Predictions'] = forecast_valid.values
    plt.plot(train_set['y'])
    plt.plot(valid_set[['y', 'Predictions']])
    plt.xlabel('Date', size=20)
    plt.ylabel('Stock Price', size=20)
    plt.title('Stock Price Prediction by Exponential Smoothing', size=20)
    plt.legend(['Model Training Data', 'Actual Data', 'Predicted Data'])

exp_smoothing_prediction(df)

